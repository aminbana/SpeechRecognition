{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech_ASR_english_ctc_continue.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36ea746fec8645ddb8886c68c9009fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e1e737bfb7a440a89b6e0675cb298811",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a5e7764e9c9042599fa43217b664d719",
              "IPY_MODEL_5edfc07846174d3faea62a3c9cf0e831"
            ]
          }
        },
        "e1e737bfb7a440a89b6e0675cb298811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5e7764e9c9042599fa43217b664d719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cc1665599efe407baa1c1a80f9591148",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 6387309499,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6387309499,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b0c44dac0fd48a5b2e0b58c53a2d2d9"
          }
        },
        "5edfc07846174d3faea62a3c9cf0e831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9263ebd93bc94724a5c647806ce4fc1c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.95G/5.95G [13:14&lt;00:00, 8.04MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3fa674306cb64a53a84c7e071771a9ff"
          }
        },
        "cc1665599efe407baa1c1a80f9591148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b0c44dac0fd48a5b2e0b58c53a2d2d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9263ebd93bc94724a5c647806ce4fc1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3fa674306cb64a53a84c7e071771a9ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ea9030d8d7f4cb8a5d52f739bdacbe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0779912b7b5a4d5b9491807e77c88748",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_08ad5a26413445ad9c9c11e73525d641",
              "IPY_MODEL_7f8c2bbf37294cc6aebafb318ece2d47"
            ]
          }
        },
        "0779912b7b5a4d5b9491807e77c88748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08ad5a26413445ad9c9c11e73525d641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a8e2e6e003ed49deab05b3c2984cf9b9",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 346663984,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 346663984,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_676a2286cec34d8d9740e2ef31d6e0d5"
          }
        },
        "7f8c2bbf37294cc6aebafb318ece2d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7845cc19551345928c091669db7ebd37",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 331M/331M [00:37&lt;00:00, 9.19MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_555bfdada47a4d40866bd9d5fd197dcf"
          }
        },
        "a8e2e6e003ed49deab05b3c2984cf9b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "676a2286cec34d8d9740e2ef31d6e0d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7845cc19551345928c091669db7ebd37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "555bfdada47a4d40866bd9d5fd197dcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a81eb0c85f0644edb7feceb93a084c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_413a8411954049418e5fc6029027eb0a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_31e702ce423a48a7a5ac263bccdf883c",
              "IPY_MODEL_4cd3db52c9da4bf7ad6173cf50784593"
            ]
          }
        },
        "413a8411954049418e5fc6029027eb0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31e702ce423a48a7a5ac263bccdf883c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ad10c9ea12a0487496e1ccb04f61d950",
            "_dom_classes": [],
            "description": "  5%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 20,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2758f1a1ea8b4cdb9caed963456d7fd5"
          }
        },
        "4cd3db52c9da4bf7ad6173cf50784593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e5dcdd27684c4e3da2d3f03ec84e8359",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/20 [2:14:29&lt;42:35:25, 8069.77s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33a50a619db64354a5d5ca1c8e3c01a2"
          }
        },
        "ad10c9ea12a0487496e1ccb04f61d950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2758f1a1ea8b4cdb9caed963456d7fd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5dcdd27684c4e3da2d3f03ec84e8359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33a50a619db64354a5d5ca1c8e3c01a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf36805f6e4d432298224e26fd266d66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_709af5dfe5244d2fb705e069aa225de6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_66fcb86315e44be792e0a28146ebff95",
              "IPY_MODEL_95bf944069d64015a832b75616069fe0"
            ]
          }
        },
        "709af5dfe5244d2fb705e069aa225de6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "66fcb86315e44be792e0a28146ebff95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_368c0f6781814a53b120332e39c25ae9",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2854,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2854,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_653b36a066d84110b0ce0e505f81e929"
          }
        },
        "95bf944069d64015a832b75616069fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9348a325f57e46e09e6fdcd25c532214",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2854/2854 [1:43:25&lt;00:00,  2.17s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5deff977b531462789f4ae9881189862"
          }
        },
        "368c0f6781814a53b120332e39c25ae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "653b36a066d84110b0ce0e505f81e929": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9348a325f57e46e09e6fdcd25c532214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5deff977b531462789f4ae9881189862": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b667943d37c493ca3737a54165aa2eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f5b7bbd541734403bb4f6fc922db570e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f5afb6c0215743ebaf9d6a067c8a2d22",
              "IPY_MODEL_39ea558049294a0da15c01dc8a259604"
            ]
          }
        },
        "f5b7bbd541734403bb4f6fc922db570e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5afb6c0215743ebaf9d6a067c8a2d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_552d4028a5eb46a8aa9af5534c5d938c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 262,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 262,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b3a03a5f7b144a59e8ce131d32f8f93"
          }
        },
        "39ea558049294a0da15c01dc8a259604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c7c8b68f107043e3aa163cc7c1b42de3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 262/262 [31:03&lt;00:00,  7.11s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bdef48c7b50f45c9853d888824810579"
          }
        },
        "552d4028a5eb46a8aa9af5534c5d938c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b3a03a5f7b144a59e8ce131d32f8f93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7c8b68f107043e3aa163cc7c1b42de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bdef48c7b50f45c9853d888824810579": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca2cea92f68648849714d35a8d2d9381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_01583f42a5ed49c594757ff2c558aa62",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_91c7ffc8d940488482cbebf1e94fff14",
              "IPY_MODEL_b8e44b1889ed476591af01f855cb4c5b"
            ]
          }
        },
        "01583f42a5ed49c594757ff2c558aa62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91c7ffc8d940488482cbebf1e94fff14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c68f7a32efaa4cc68fc2d779cffd2ca0",
            "_dom_classes": [],
            "description": " 35%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 2854,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68a382f229fe4eada7c67554d61dd59e"
          }
        },
        "b8e44b1889ed476591af01f855cb4c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_29247ee0477d40ac97f37016cfb7a2c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 999/2854 [36:03&lt;1:06:55,  2.16s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55e4ed0c453e4aa6b32877a899c25e11"
          }
        },
        "c68f7a32efaa4cc68fc2d779cffd2ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68a382f229fe4eada7c67554d61dd59e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29247ee0477d40ac97f37016cfb7a2c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55e4ed0c453e4aa6b32877a899c25e11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ap14oBSfeUY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "a6be0bcb-92d2-4097-c160-f7df8e8b147a"
      },
      "source": [
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install torchaudio"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.6.0+cu101 in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: torchvision==0.7.0+cu101 in /usr/local/lib/python3.6/dist-packages (0.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0+cu101) (7.0.0)\n",
            "Collecting torchaudio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/34/c651430dea231e382ddf2eb5773239bf4885d9528f640a4ef39b12894cb8/torchaudio-0.6.0-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.7MB 78kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.6/dist-packages (from torchaudio) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->torchaudio) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->torchaudio) (0.16.0)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnDT0p6ZCstV",
        "colab_type": "text"
      },
      "source": [
        "# Flags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC4-06_lauyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PERSIAN_FLAG = False\n",
        "SEQ2SEQ_Training = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h12HUz9xlSzQ",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHHp-gyyCwoB",
        "colab_type": "text"
      },
      "source": [
        "## Text transform class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z-YoyferuUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "class TextTransform:\n",
        "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
        "    def __init__(self):\n",
        "        char_map_str = \"\"\"\n",
        "        ' 0\n",
        "        <SPACE> 1\n",
        "        a 2\n",
        "        b 3\n",
        "        c 4\n",
        "        d 5\n",
        "        e 6\n",
        "        f 7\n",
        "        g 8\n",
        "        h 9\n",
        "        i 10\n",
        "        j 11\n",
        "        k 12\n",
        "        l 13\n",
        "        m 14\n",
        "        n 15\n",
        "        o 16\n",
        "        p 17\n",
        "        q 18\n",
        "        r 19\n",
        "        s 20\n",
        "        t 21\n",
        "        u 22\n",
        "        v 23\n",
        "        w 24\n",
        "        x 25\n",
        "        y 26\n",
        "        z 27\n",
        "        > 28\n",
        "        < 29\n",
        "        \"\"\"\n",
        "        if PERSIAN_FLAG:\n",
        "          char_map_str = \"\"\"\n",
        "          = 0\n",
        "          o 1 \n",
        "          l 2 \n",
        "          g 3\n",
        "          e 4\n",
        "          t 5\n",
        "          p 6\n",
        "          / 7\n",
        "          z 8\n",
        "          ] 9\n",
        "          v 10\n",
        "          j 11\n",
        "          m 12\n",
        "          x 13\n",
        "          s 14\n",
        "          q 15\n",
        "          r 16\n",
        "          a 17\n",
        "          [ 18\n",
        "          d 19\n",
        "          , 20\n",
        "          ' 21\n",
        "          f 22\n",
        "          y 23\n",
        "          b 24\n",
        "          <SPACE> 25\n",
        "          k 26\n",
        "          n 27\n",
        "          h 28\n",
        "          u 29\n",
        "          . 30\n",
        "          i 31\n",
        "          > 32\n",
        "          < 33\n",
        "          \"\"\"\n",
        "\n",
        "        self.start_token = '<'\n",
        "        self.stop_token = '>'\n",
        "        self.pad_token = '=' if PERSIAN_FLAG else \"'\"\n",
        "\n",
        "        self.char_map = {}\n",
        "        self.index_map = {}\n",
        "        for line in char_map_str.strip().split('\\n'):\n",
        "            ch, index = line.split()\n",
        "            self.char_map[ch] = int(index)\n",
        "            self.index_map[int(index)] = ch\n",
        "        if PERSIAN_FLAG:\n",
        "          self.index_map[25] = ' '\n",
        "        else:\n",
        "          self.index_map[1] = ' '\n",
        "\n",
        "    def text_to_int(self, text):\n",
        "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
        "        int_sequence = []\n",
        "        for c in text:\n",
        "            if c == ' ':\n",
        "                ch = self.char_map['<SPACE>']\n",
        "            else:\n",
        "                ch = self.char_map[c]\n",
        "            int_sequence.append(ch)\n",
        "        return int_sequence\n",
        "\n",
        "    def int_to_text(self, labels):\n",
        "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
        "        string = []\n",
        "        for i in labels:\n",
        "            string.append(self.index_map[i])\n",
        "        return ''.join(string).replace('<SPACE>', ' ')\n",
        "\n",
        "if PERSIAN_FLAG:\n",
        "  sample_rate = 16000\n",
        "else:\n",
        "  sample_rate = 22050\n",
        "\n",
        "train_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate, n_mels=128),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "\n",
        "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
        "\n",
        "text_transform = TextTransform()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky3bnV9hDyXV",
        "colab_type": "text"
      },
      "source": [
        "## Collate function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV8MFalRqYI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_processing(data, data_type=\"train\"):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "\n",
        "    waveforms = []\n",
        "\n",
        "    for (waveform, _, utterance, _, _, _) in data:\n",
        "\n",
        "        waveforms.append (waveform)\n",
        "\n",
        "        if data_type == 'train':\n",
        "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        elif data_type == 'valid':\n",
        "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        else:\n",
        "            raise Exception('data_type should be train or valid')\n",
        "        \n",
        "        spectrograms.append(spec)\n",
        "        utterance = '<' + utterance + '>'\n",
        "        \n",
        "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "        labels.append(label)\n",
        "\n",
        "        input_lengths.append(spec.shape[0]//2)\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3) \n",
        "    # n_batch , n_channels = 1, n_feats = 128 , n_seq = variable and equal to longest waveform in batch\n",
        "\n",
        "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "    # n_batch, n_seq = variable and equal to longest utterance in batch\n",
        "    \n",
        "    return waveforms, spectrograms, labels, input_lengths, label_lengths\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvpgdYycD4fz",
        "colab_type": "text"
      },
      "source": [
        "## Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHeN-TQobFby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.io import wavfile\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import glob\n",
        "import torch\n",
        "\n",
        "\n",
        "class FarsDot(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_set):\n",
        "        self.dataset = data_set\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        waveform = torch.tensor (self.dataset[index]['data'], dtype = torch.float32)\n",
        "        utterance = self.dataset[index]['text']\n",
        "        return (\n",
        "        waveform,\n",
        "        _,\n",
        "        utterance,\n",
        "        _,\n",
        "        _,\n",
        "        _,\n",
        "    )\n",
        "\n",
        "    def __len__(self):        \n",
        "        return len (self.dataset)\n",
        "    \n",
        "def extract_samples(path = \"CD2/\" , max_limit = 30):\n",
        "\n",
        "    \n",
        "    wave_files = os.listdir(path + \"wave/\")\n",
        "\n",
        "    waves = []\n",
        "\n",
        "    print (\"reading audio files ... \")\n",
        "    count = 0\n",
        "    for wave_file in tqdm (wave_files):\n",
        "    \n",
        "        fs, data = wavfile.read(path + \"wave/\" + wave_file)\n",
        "        data = data/np.max([np.abs (data.max()), np.abs (data.min())])\n",
        "        assert fs == 22050\n",
        "    \n",
        "        sentences = []\n",
        "        with open(path + \"SENTENCE/\" + wave_file.split('.')[0] + '.SNT' , 'r') as sentence_file:\n",
        "            for line in sentence_file:\n",
        "                sentences.append (line)\n",
        "    \n",
        "        waves.append ({'data':data, 'id':int (wave_file.split('.')[0][1:]) , 'sentences':sentences})\n",
        "        \n",
        "        count += 1\n",
        "        if max_limit is not None and count > max_limit:\n",
        "            break\n",
        "    \n",
        "    samples = []\n",
        "    letters_dictionary = []\n",
        "\n",
        "    corpus = []\n",
        "    print (\"parsing sentences ... \")\n",
        "    for wave in tqdm (waves):\n",
        "        for line in wave['sentences']:\n",
        "            sent_id , start, stop = line.split ()\n",
        "            sent_id = int (sent_id)\n",
        "            start = int (start) // 2\n",
        "            stop = int (stop) // 2\n",
        "\n",
        "            text = []\n",
        "            with open (path + 'WORD/W' + str(wave['id']) + '.' + str(sent_id), 'r') as f:\n",
        "                for l in f:\n",
        "                    text.append (l.split()[0])\n",
        "            # text = text[1:] #ignoring first j\n",
        "\n",
        "            text = ' '.join(text)\n",
        "            \n",
        "            for t in text:\n",
        "                if t not in letters_dictionary:\n",
        "                    letters_dictionary.append (t)\n",
        "\n",
        "            samples.append ({'data':wave['data'][start:stop] , 'file_id':wave['id'] , 'sentence_id':sent_id, 'text':text} )\n",
        "            \n",
        "            corpus.append (text)\n",
        "    \n",
        "    with open (\"corpus.txt\" , 'w') as f:\n",
        "      for s in corpus:\n",
        "          f.write(\"%s\\n\" % s)\n",
        "        \n",
        "    \n",
        "    letters_dictionary = set (letters_dictionary)\n",
        "        \n",
        "    return samples , letters_dictionary"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMRF9KT9EH7C",
        "colab_type": "text"
      },
      "source": [
        "## Load dataset from disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm3paPfMbSp7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "805ccf4a-3322-4d6c-9b45-194c9fa17eae"
      },
      "source": [
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrRsew0ga6P6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114,
          "referenced_widgets": [
            "36ea746fec8645ddb8886c68c9009fc3",
            "e1e737bfb7a440a89b6e0675cb298811",
            "a5e7764e9c9042599fa43217b664d719",
            "5edfc07846174d3faea62a3c9cf0e831",
            "cc1665599efe407baa1c1a80f9591148",
            "8b0c44dac0fd48a5b2e0b58c53a2d2d9",
            "9263ebd93bc94724a5c647806ce4fc1c",
            "3fa674306cb64a53a84c7e071771a9ff",
            "9ea9030d8d7f4cb8a5d52f739bdacbe0",
            "0779912b7b5a4d5b9491807e77c88748",
            "08ad5a26413445ad9c9c11e73525d641",
            "7f8c2bbf37294cc6aebafb318ece2d47",
            "a8e2e6e003ed49deab05b3c2984cf9b9",
            "676a2286cec34d8d9740e2ef31d6e0d5",
            "7845cc19551345928c091669db7ebd37",
            "555bfdada47a4d40866bd9d5fd197dcf"
          ]
        },
        "outputId": "015c7f87-0a58-4a5a-87e6-0beccfa5b534"
      },
      "source": [
        "def permute_split_dataset (full_dataset, test_ratio):\n",
        "\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    perm_indices = np.random.permutation(len (full_dataset))\n",
        "    eval_dataset = [v for j,v in enumerate (full_dataset) if j in perm_indices [:int (test_ratio * len(full_dataset))]]\n",
        "    train_phase_dataset = [v for j,v in enumerate (full_dataset) if j not in perm_indices [:int (test_ratio * len(full_dataset))]]\n",
        "    return train_phase_dataset, eval_dataset\n",
        "\n",
        "if PERSIAN_FLAG:\n",
        "  # s1 , l1 = extract_samples(path = \"/content/drive/My Drive/ASR/CD1/\" , max_limit = None)\n",
        "  # s2 , l2 = extract_samples(path = \"/content/drive/My Drive/ASR/CD2/\" , max_limit = None)\n",
        "\n",
        "  # with open(\"/content/drive/My Drive/ASR/cd1.dat\", 'wb') as f:\n",
        "  #   torch.save(s1, f)\n",
        "  # with open(\"/content/drive/My Drive/ASR/cd2.dat\", 'wb') as f:\n",
        "  #   torch.save(s2, f)\n",
        "\n",
        "  with open(\"/content/drive/My Drive/ASR/cd1.dat\", 'rb') as f:\n",
        "    s1 = torch.load(f)\n",
        "  with open(\"/content/drive/My Drive/ASR/cd2.dat\", 'rb') as f:\n",
        "    s2 = torch.load(f)\n",
        "  \n",
        "  total_dataset = s1 + s2\n",
        "  #fixme\n",
        "  train_dataset, test_dataset = permute_split_dataset(total_dataset , 0.2)\n",
        "\n",
        "  train_dataset = FarsDot(train_dataset)\n",
        "  test_dataset = FarsDot(test_dataset)\n",
        "\n",
        "else:\n",
        "  if not os.path.isdir(\"./data\"):\n",
        "    os.makedirs(\"./data\")\n",
        "\n",
        "  train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=\"train-clean-100\", download=True)\n",
        "  # train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=\"test-clean\", download=True)\n",
        "  test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=\"test-clean\", download=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36ea746fec8645ddb8886c68c9009fc3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=6387309499.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ea9030d8d7f4cb8a5d52f739bdacbe0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=346663984.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFdi6RKQEMI_",
        "colab_type": "text"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjFQEtp-lQOc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                            batch_size=10,\n",
        "                            shuffle=True,\n",
        "                            collate_fn=lambda x: data_processing(x, 'train'),\n",
        "                            num_workers= 4, pin_memory= True)\n",
        "\n",
        "test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                            batch_size=10,\n",
        "                            shuffle=True,\n",
        "                            collate_fn=lambda x: data_processing(x, 'valid'),\n",
        "                            num_workers= 4, pin_memory= True)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvVt3594lQ5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = next (iter (train_loader))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeAA-FGf6Bse",
        "colab_type": "text"
      },
      "source": [
        "# Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjk_CY6n3WY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "USE_LM_Model = False"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RimgUeoi2O9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text_corpus(train_dataset):\n",
        "  text_corpus = []\n",
        "  for _,_,utterance,_,_,_ in train_dataset:\n",
        "    text_corpus.append (text_transform.start_token + utterance + text_transform.stop_token)\n",
        "  return text_corpus\n",
        "if USE_LM_Model:\n",
        "  text_corpus = generate_text_corpus(train_dataset)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvFL11ZjCiE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LM_collate_fn(batch):\n",
        "    labels = []\n",
        "    for utterance in batch:\n",
        "      label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "      labels.append(label)\n",
        "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=False) \n",
        "    return labels\n",
        "if USE_LM_Model:\n",
        "  LM_train_loader = data.DataLoader(dataset = text_corpus,\n",
        "                              batch_size=10,\n",
        "                              shuffle = True,\n",
        "                              collate_fn = LM_collate_fn,\n",
        "                              num_workers= 4, pin_memory= True)\n",
        "\n",
        "\n",
        "  a = next (iter (LM_train_loader))\n",
        "\n",
        "  print (a.shape)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xbhqu2_I6FE9",
        "colab_type": "text"
      },
      "source": [
        "## LM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1LmHo1B3lGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LangualeModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LangualeModel, self).__init__()\n",
        "    if PERSIAN_FLAG:\n",
        "      n_class = 32 + 2 + 1# +2 for start and stop tokens , +1 for pad token\n",
        "    else:\n",
        "      n_class = 29 + 2 # +2 for start and stop tokens\n",
        "\n",
        "    self.vocab_size = n_class\n",
        "    self.embeding_size = 100\n",
        "    self.hidden_size = 512\n",
        "    self.embedding = torch.nn.Embedding(num_embeddings = self.vocab_size, embedding_dim = self.embeding_size, padding_idx=text_transform.char_map [text_transform.pad_token])\n",
        "    self.rnn = nn.LSTM(input_size = self.embeding_size, hidden_size = self.hidden_size, num_layers = 1, bias = True, batch_first = False)\n",
        "    self.output_projection = nn.Linear (self.hidden_size, self.vocab_size , bias=False)\n",
        "\n",
        "  def get_logits(self, sent, init_hidden_states = None):\n",
        "    DEVICE = next (self.parameters()).device\n",
        "    batch_size = sent.shape[1]\n",
        "    if init_hidden_states is None:\n",
        "      init_hidden_states = [torch.zeros ([1,batch_size, self.hidden_size] , requires_grad = False).to(DEVICE),\n",
        "                                  torch.zeros ([1,batch_size, self.hidden_size] , requires_grad = False).to(DEVICE)]\n",
        "    embedded_sents = self.embedding (sent)\n",
        "    output, last_hidden = self.rnn(embedded_sents, init_hidden_states)\n",
        "    logits = self.output_projection (output)\n",
        "    return logits, last_hidden\n",
        "\n",
        "  def forward(self,full_sentences):\n",
        "    full_sentences = full_sentences.long()\n",
        "    sent = full_sentences[:-1]\n",
        "    logits, _ = self.get_logits(sent)\n",
        "    \n",
        "    sent_mask = (full_sentences != 0).float()    \n",
        "    log_probs = F.log_softmax(logits, dim=-1)\n",
        "    # Compute log probability of generating true target words\n",
        "    tgt_gold_words_log_prob = torch.gather(log_probs, index=full_sentences[1:].unsqueeze(-1), dim=-1).squeeze(-1) * sent_mask[1:]\n",
        "    scores = tgt_gold_words_log_prob.sum(dim=0)\n",
        "    \n",
        "    return scores\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8dNME7JHwfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if USE_LM_Model:\n",
        "  LM_model = LangualeModel().cuda()\n",
        "  optimizer = optim.Adam(LM_model.parameters(), 5e-4)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeRcALXmGjZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if USE_LM_Model:\n",
        "  print (\"Training LM model, be patient...\")\n",
        "  for epoch in tqdm (range (5)):\n",
        "    loss_avg = 0\n",
        "    n_batch = 0\n",
        "    for batch in tqdm (LM_train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      batch_size = len (batch)\n",
        "      scores = LM_model (batch.cuda())\n",
        "      loss = -scores.sum()/batch_size\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      loss_avg = (loss.item() * batch_size + loss_avg * n_batch) / (batch_size + n_batch) \n",
        "    print (\"average loss :\" , loss_avg)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUXFLcnIxSkR",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tcwRzjb__PA",
        "colab_type": "text"
      },
      "source": [
        "## CTC-Based model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYHxFEgNlFun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNLayerNorm(nn.Module):\n",
        "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
        "    def __init__(self, n_feats):\n",
        "        super(CNNLayerNorm, self).__init__()\n",
        "        self.layer_norm = nn.LayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x (batch, channel, feature, time)\n",
        "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
        "        x = self.layer_norm(x)\n",
        "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time) \n",
        "\n",
        "\n",
        "class ResidualCNN(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
        "        super(ResidualCNN, self).__init__()\n",
        "\n",
        "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
        "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x  # (batch, channel, feature, time)\n",
        "        x = self.layer_norm1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.cnn1(x)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.cnn2(x)\n",
        "        x += residual\n",
        "        return x # (batch, channel, feature, time)\n",
        "\n",
        "\n",
        "class BidirectionalGRU(nn.Module):\n",
        "\n",
        "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
        "        super(BidirectionalGRU, self).__init__()\n",
        "\n",
        "        self.BiGRU = nn.GRU(\n",
        "            input_size=rnn_dim, hidden_size=hidden_size,\n",
        "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
        "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_norm(x)\n",
        "        x = F.gelu(x)\n",
        "        x, _ = self.BiGRU(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SpeechRecognitionModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
        "        super(SpeechRecognitionModel, self).__init__()\n",
        "        n_feats = n_feats//2\n",
        "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
        "\n",
        "        # n residual cnn layers with filter size of 32\n",
        "        self.rescnn_layers = nn.Sequential(*[\n",
        "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
        "            for _ in range(n_cnn_layers)\n",
        "        ])\n",
        "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
        "        self.birnn_layers = nn.Sequential(*[\n",
        "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
        "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
        "            for i in range(n_rnn_layers)\n",
        "        ])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(rnn_dim, n_class)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = self.rescnn_layers(x)\n",
        "        sizes = x.size()\n",
        "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
        "        x = x.transpose(1, 2) # (batch, time, feature)\n",
        "        x = self.fully_connected(x)\n",
        "        x = self.birnn_layers(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ6AjCe9kmxh",
        "colab_type": "text"
      },
      "source": [
        "## Seq2Seq Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMtJwAIPAaLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "\n",
        "class AttnDecoder(nn.Module):\n",
        "    def __init__(self, hidden_size: int, embed_size: int, tgt_vocab_size: int, dropout_rate=0.2):\n",
        "        \"\"\"\n",
        "        hidden_size: hidden size to be used for the RNN\n",
        "        embed_size: embedding size (dimension)\n",
        "        tgt_vocab_size: target language vocab size \n",
        "        dropout_rate: rate to be used for the dropout layer \n",
        "        \"\"\"\n",
        "        super(AttnDecoder, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.tgt_vocab_size = tgt_vocab_size\n",
        "        self.rnn = None\n",
        "        self.dropout = None\n",
        "        self.tgt_vocab_projection = None  \n",
        "        self.attn_combine = None \n",
        "        self.tgt_embedding = None\n",
        "        self.text_transform = text_transform\n",
        "        self.tgt_embedding = torch.nn.Embedding(num_embeddings = self.tgt_vocab_size, embedding_dim = self.embed_size\n",
        "                                                , padding_idx=self.text_transform.char_map [self.text_transform.pad_token])\n",
        "        self.rnn = torch.nn.GRUCell(input_size = self.embed_size + self.hidden_size, hidden_size = self.hidden_size)# bias=False)\n",
        "\n",
        "        self.attn_combine = torch.nn.Linear( 2 * hidden_size, hidden_size, bias=False)\n",
        "        self.tgt_vocab_projection = torch.nn.Linear(hidden_size, self.tgt_vocab_size, bias=False)\n",
        "        self.dropout = torch.nn.Dropout (dropout_rate)\n",
        "    \n",
        "    def get_logits(self, enc_hiddens, enc_hiddens_mask, tgt, dec_init_state, combined_output_prev = None):\n",
        "        dec_state = dec_init_state\n",
        "        batch_size = enc_hiddens.size(0)\n",
        "        DEVICE = next(self.parameters()).device\n",
        "        if combined_output_prev is None:\n",
        "            combined_output_prev = torch.zeros(batch_size, self.hidden_size, device=DEVICE)\n",
        "        combined_outputs = []\n",
        "        embeded_target = self.tgt_embedding (tgt)\n",
        "        for t, y_t in enumerate (embeded_target):\n",
        "          ybar_t = torch.cat ((y_t, combined_output_prev) , dim = -1)\n",
        "          dec_state , combined_output_prev = self.step(ybar_t , dec_state, enc_hiddens, enc_hiddens_mask)\n",
        "          combined_outputs.append (combined_output_prev)\n",
        "        combined_outputs = torch.stack (combined_outputs)\n",
        "        projected = self.tgt_vocab_projection (combined_outputs)\n",
        "        logits = projected\n",
        "\n",
        "        return logits, dec_state, combined_output_prev\n",
        "\n",
        "    \n",
        "    def forward(self, enc_hiddens: torch.Tensor, enc_hiddens_mask: torch.Tensor, \n",
        "                tgt: torch.Tensor, dec_init_state: torch.Tensor = None, combined_output_prev = None):        \n",
        "        tgt = tgt[:-1]\n",
        "        logits, _, _ = self.get_logits(enc_hiddens, enc_hiddens_mask, tgt, dec_init_state, combined_output_prev)\n",
        "        return logits\n",
        "\n",
        "        \n",
        "    def step(self, ybar_t: torch.Tensor, dec_state: torch.Tensor, enc_hiddens: torch.Tensor, enc_hiddens_mask):\n",
        "        \"\"\"\n",
        "        ybar_t: the input to be fed to the decoder at the current step with shape\n",
        "        dec_state: decodor's previous hidden state \n",
        "        enc_hiddens: encoder hidden states (outputs)\n",
        "        enc_hiddens_mask: mask generated during the encoding phase that masks <PAD>s \n",
        "\n",
        "        returns the current hidden state and combined output\n",
        "        \"\"\"\n",
        "        attn_scores_t, dec_state_t = None, None\n",
        "        \n",
        "        dec_state_t = self.rnn(ybar_t,dec_state)\n",
        "        # print (\"enc_hiddens.shape:\", enc_hiddens.shape, \"dec_state_t.unsqueeze(-1).shape\", dec_state_t.unsqueeze(-1).shape)\n",
        "        attn_scores_t = torch.bmm (enc_hiddens , dec_state_t.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "        if enc_hiddens_mask is not None:\n",
        "            attn_scores_t.data.masked_fill_(enc_hiddens_mask.bool(), -float('inf'))\n",
        "\n",
        "        combined_output_t = None\n",
        "        \n",
        "        atten_dist = torch.nn.Softmax(dim=-1)(attn_scores_t)\n",
        "\n",
        "        \n",
        "        context_vector = enc_hiddens * atten_dist[:,:,None]\n",
        "        context_vector = context_vector.sum(dim = 1)\n",
        "        \n",
        "        concated_tensor = torch.cat((dec_state_t, context_vector) , dim = -1)\n",
        "        combined_output_t = self.dropout (torch.tanh(self.attn_combine (concated_tensor)))\n",
        "        \n",
        "        return dec_state_t, combined_output_t\n",
        "\n",
        "\n",
        "class Seq2Seq_SpeechRecognitionModel(nn.Module):\n",
        "    \n",
        "    def generate_enc_hiddens_mask(self, enc_hiddens, lengths):\n",
        "        \"\"\"Generates mask which masks the encoder hidden states corresponding to <PAD> tokens \n",
        "        in the source sentences\n",
        "        \"\"\"\n",
        "        DEVICE = next (self.parameters()).device\n",
        "        enc_masks = torch.zeros(enc_hiddens.shape[0], enc_hiddens.size(1), dtype=torch.float)\n",
        "        for iterator, length in enumerate(lengths):\n",
        "            enc_masks[iterator, length:] = 1\n",
        "\n",
        "        return enc_masks.to(DEVICE)\n",
        "    \n",
        "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
        "        super(Seq2Seq_SpeechRecognitionModel, self).__init__()\n",
        "        \n",
        "        self.encoder_hidden_size = 512\n",
        "        self.decoder_hidden_size = 512\n",
        "        self.encoder_gru = torch.nn.GRU(input_size  = n_feats , hidden_size = self.encoder_hidden_size, num_layers = 2, bidirectional = True)\n",
        "        \n",
        "        self.bridge = nn.Linear(self.encoder_hidden_size * 2, self.decoder_hidden_size, bias = False)\n",
        "        self.decoder = AttnDecoder(hidden_size = self.decoder_hidden_size, embed_size = 100, tgt_vocab_size = n_class) \n",
        "        self.text_transform = text_transform\n",
        "        \n",
        "    def encoder(self,x,input_lengths):\n",
        "        x = x[:,0].permute([2,0,1])\n",
        "        batch_size = x.shape[1]\n",
        "        seq_len = x.shape[0]\n",
        "        \n",
        "        enc_hiddens, last_hiddens = self.encoder_gru(x)\n",
        "        last_hiddens = last_hiddens.reshape([2, 2, batch_size, self.encoder_hidden_size])\n",
        "        last_hiddens = last_hiddens[-1].permute ([1,0,2])\n",
        "        last_hiddens = last_hiddens.reshape([batch_size, 2*self.encoder_hidden_size])\n",
        "        \n",
        "        enc_hiddens = enc_hiddens.reshape([seq_len, batch_size, 2 , self.encoder_hidden_size])\n",
        "        enc_hiddens = enc_hiddens[::2,:,1,:]\n",
        "        enc_masks = self.generate_enc_hiddens_mask(enc_hiddens, input_lengths)\n",
        "        enc_hiddens = enc_hiddens.permute ([1,0,2])\n",
        "        enc_masks = enc_masks.permute ([1,0])\n",
        "\n",
        "        return enc_hiddens, last_hiddens, enc_masks\n",
        "    \n",
        "    def forward(self, x, labels, input_lengths):\n",
        "        enc_hiddens, last_hiddens, enc_masks = self.encoder (x, input_lengths)\n",
        "        \n",
        "        init_hiddens = self.bridge(last_hiddens)\n",
        "        \n",
        "        tgt_tensor = labels.permute([1,0]).long() #time, batch\n",
        "        logits = self.decoder(enc_hiddens = enc_hiddens, enc_hiddens_mask = enc_masks, tgt= tgt_tensor, dec_init_state = init_hiddens, combined_output_prev = None)\n",
        "        \n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        tgt_mask = (tgt_tensor != 0).float()\n",
        "        tgt_gold_words_log_prob = torch.gather(log_probs, index=tgt_tensor[1:].unsqueeze(-1), dim=-1).squeeze(-1) * tgt_mask[1:]\n",
        "        scores = tgt_gold_words_log_prob.sum(dim=0)\n",
        "\n",
        "        return scores            \n",
        "\n",
        "    def decode_one_beam(self, beam, enc_hiddens, enc_masks, k):\n",
        "        DEVICE = next(self.parameters()).device\n",
        "        token = torch.tensor ([beam['tokens'][-1]])\n",
        "        sentences = token[None].to(DEVICE)\n",
        "        \n",
        "        logits, hidden_state, combined_out_prev = self.decoder.get_logits(enc_hiddens, enc_masks, sentences,\n",
        "                                                                          dec_init_state = beam['last_hidden'], combined_output_prev = beam['combined_out_prev'])\n",
        "        \n",
        "        probs = logits.softmax(dim=-1)\n",
        "\n",
        "        LM_hiddens = None\n",
        "        if USE_LM_Model:\n",
        "          LM_hiddens = beam['LM_init_hidden']\n",
        "          lm_logits, LM_hiddens = LM_model.get_logits(sentences, LM_hiddens)\n",
        "          lm_probs = logits.softmax(dim=-1)\n",
        "          probs = probs * lm_probs\n",
        "\n",
        "        probs, idxs = torch.topk (probs, k)\n",
        "        probs = probs.reshape([k])\n",
        "\n",
        "        idxs = idxs.reshape([k])\n",
        "        \n",
        "        res = []\n",
        "        for i in range(probs.shape[0]):\n",
        "            res.append({\"last_hidden\":hidden_state, \"combined_out_prev\":combined_out_prev, \"LM_init_hidden\":LM_hiddens, \n",
        "                        \"prob\": probs[i].log().item() + beam['prob'] , \"tokens\": beam['tokens']+[idxs[i].item()]})        \n",
        "        return res\n",
        "\n",
        "\n",
        "                    \n",
        "    def BeamDecode_one_data (self, spectrogram, input_length, max_length = 50, k = 5):\n",
        "      DEVICE = next (self.parameters()).device\n",
        "      enc_hiddens, last_hiddens, enc_masks = self.encoder (spectrogram[None], [input_length])\n",
        "      token = text_transform.text_to_int (self.text_transform.start_token)[0]\n",
        "      \n",
        "      beams_queue = [{\"tokens\": [token], \"prob\": 0, \"last_hidden\": self.bridge(last_hiddens), \"combined_out_prev\":None, \"LM_init_hidden\" : None}]\n",
        "      \n",
        "      completed_beams = []\n",
        "      beam_size = k\n",
        "  \n",
        "      for i in range (max_length):\n",
        "        new_beams_queue = []\n",
        "        for beam in beams_queue:\n",
        "            new_beams_queue += self.decode_one_beam (beam, enc_hiddens, enc_masks, k)\n",
        "        \n",
        "        beams_queue = sorted(new_beams_queue, key=lambda x: x['prob'], reverse=True)[:beam_size]\n",
        "        next_beams_queue = []\n",
        "        for j in range(len(beams_queue)):\n",
        "          if not (beams_queue[j]['tokens'][-1] == text_transform.text_to_int (text_transform.stop_token)[0]):\n",
        "            next_beams_queue.append (beams_queue[j])\n",
        "          else:\n",
        "            beam_size -= 1\n",
        "            completed_beams.append(beams_queue[j])\n",
        "            \n",
        "        beams_queue = next_beams_queue\n",
        "            \n",
        "        if (beam_size <= 0):\n",
        "            break\n",
        "    \n",
        "      if (len(completed_beams) == 0):\n",
        "        completed_beams = beams_queue\n",
        "            \n",
        "      tokens_list = max(completed_beams, key=lambda x: x['prob'])['tokens']\n",
        "      \n",
        "      return \"\".join (text_transform.int_to_text(tokens_list))\n",
        "\n",
        "    def beam_decode(self, spectrograms, input_lengths, max_length = 50, k = 5):\n",
        "        decoded_batch = []\n",
        "        for j in range (len (spectrograms)):\n",
        "            decoded_batch.append (self.BeamDecode_one_data(spectrograms[j], input_lengths[j], max_length, k))\n",
        "        return decoded_batch\n",
        "            \n",
        "                  \n",
        "    def greedy_decode(self, spectrograms, input_lengths, max_length = 50):\n",
        "        DEVICE = next (self.parameters()).device\n",
        "        decoded_batch = []\n",
        "        for j in range (len (spectrograms)):\n",
        "            enc_hiddens, last_hiddens, enc_masks = self.encoder (spectrograms[j][None], [input_lengths[j]])\n",
        "            init_hiddens = self.bridge(last_hiddens)\n",
        "            \n",
        "            labels = []\n",
        "            \n",
        "            dec_state = init_hiddens\n",
        "            token = self.text_transform.start_token\n",
        "            labels.append(token)\n",
        "            \n",
        "            combined_output_prev = torch.zeros(1, self.decoder.hidden_size, device=DEVICE)\n",
        "\n",
        "            for i in range (max_length):\n",
        "                token = torch.tensor (self.text_transform.text_to_int (token)).to(DEVICE)\n",
        "                embeded_token = self.decoder.tgt_embedding (token)\n",
        "                ybar_t = torch.cat ((embeded_token, combined_output_prev) , dim = -1)\n",
        "\n",
        "                dec_state , combined_output_prev = self.decoder.step(ybar_t , dec_state, enc_hiddens, enc_masks)\n",
        "                projected = self.decoder.tgt_vocab_projection (combined_output_prev)\n",
        "                token = self.text_transform.int_to_text ([torch.argmax(projected).item()])[0]\n",
        "#                 print (token)\n",
        "                labels.append(token)\n",
        "                if token == text_transform.stop_token:\n",
        "                    break            \n",
        "            decoded_batch.append (\"\".join (labels))\n",
        "            \n",
        "        \n",
        "        \n",
        "        return decoded_batch \n",
        "    \n",
        "\n",
        "        "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdF-KXqbEYVh",
        "colab_type": "text"
      },
      "source": [
        "## Model instatnciation , Optimizer, Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mtmGEANk5Dg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "epochs = 20\n",
        "if PERSIAN_FLAG:\n",
        "  n_class = 32 + 2 + 1# +2 for start and stop tokens , +1 for pad token\n",
        "else:\n",
        "  n_class = 29 + 2 # +2 for start and stop tokens\n",
        "\n",
        "if SEQ2SEQ_Training:\n",
        "  n_class -= 1\n",
        "\n",
        "if SEQ2SEQ_Training:\n",
        "  model = Seq2Seq_SpeechRecognitionModel (n_cnn_layers = 3, n_rnn_layers = 5, rnn_dim = 512, n_class = n_class , n_feats = 128, stride = 2, dropout = 0.1).to(device)\n",
        "else:\n",
        "  model = SpeechRecognitionModel (n_cnn_layers = 3, n_rnn_layers = 5, rnn_dim = 1024, n_class = n_class , n_feats = 128, stride = 2, dropout = 0.1).to(device)\n",
        "\n",
        "\n",
        "if PERSIAN_FLAG:\n",
        "  criterion = nn.CTCLoss(blank=31 + 2 + 1).to(device)\n",
        "else:\n",
        "  criterion = nn.CTCLoss(blank=28 + 2).to(device)\n",
        "\n",
        "if SEQ2SEQ_Training:\n",
        "  optimizer = optim.AdamW(model.parameters(), 1e-3)  \n",
        "  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 2, gamma=0.5, last_epoch=-1)  \n",
        "else:\n",
        "  optimizer = optim.AdamW(model.parameters(), 5e-4)\n",
        "  scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=5e-4, \n",
        "                                          steps_per_epoch=int(len(train_loader)),\n",
        "                                          epochs=epochs,\n",
        "                                          anneal_strategy='linear')\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqCMdE9CjCHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a7ab3a4-164d-45eb-af09-afee4e01c11b"
      },
      "source": [
        "get_lr(optimizer)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIBK7h5PEU87",
        "colab_type": "text"
      },
      "source": [
        "## Model debug"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQfYeQc00WbJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "935e8563-58b7-4e78-801b-3f4ee472033f"
      },
      "source": [
        "debug_model = True\n",
        "if debug_model:\n",
        "  \n",
        "  for batch_idx, _data in enumerate(train_loader):\n",
        "      waveforms, spectrograms, labels, input_lengths, label_lengths = _data \n",
        "      spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "      if batch_idx > 4:\n",
        "        break\n",
        "  with open(\"sample_data.pth\" , 'wb') as f:\n",
        "    torch.save ([waveforms, spectrograms, labels, input_lengths, label_lengths] , f)\n",
        "\n",
        "  print (spectrograms.shape)\n",
        "  print (labels.shape)\n",
        "  print (input_lengths)\n",
        "  if SEQ2SEQ_Training:\n",
        "    p = model (spectrograms, labels, input_lengths)\n",
        "    loss = -p/spectrograms.shape[0]\n",
        "    print (\"decoded:\", model.beam_decode(spectrograms, input_lengths))\n",
        "  else:\n",
        "    p = model (spectrograms).transpose(0, 1) \n",
        "    loss = criterion(p, labels, input_lengths, label_lengths)\n",
        "  print (\"loss:\" , loss)\n",
        "  print (p.shape)\n",
        "  del spectrograms, _data, waveforms\n",
        "  torch.cuda.empty_cache()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 1, 128, 1304])\n",
            "torch.Size([10, 262])\n",
            "[597, 576, 252, 491, 575, 581, 602, 611, 651, 652]\n",
            "decoded: [\"<kk'kkkkckkkkkkkrrzkkkk'kkkkkcckkxkk'kkkk'kqqkkkkru\", \"<qyqyyqyoqqkrzooyolqqqyqqyqyqyokroo'ojyqqqyqqyqqkkr\", '<>', '<>', '<>', '<>', \"<qyqqkkkrkuooj'opkkkkkjroyqqqyqyqykkkjuoqqkkkkkkroo\", '<>', '<>', '<sssuq<<y>']\n",
            "loss: tensor([79.1482, 80.8888, 30.4004, 56.2788, 72.9459, 80.1796, 70.4625, 88.5504,\n",
            "        72.6496, 68.5303], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGqpk6MBEfzF",
        "colab_type": "text"
      },
      "source": [
        "# Metrics and Decoders\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54N0wc2AO6QQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def avg_wer(wer_scores, combined_ref_len):\n",
        "    return float(sum(wer_scores)) / float(combined_ref_len)\n",
        "\n",
        "\n",
        "def _levenshtein_distance(ref, hyp):\n",
        "    \"\"\"Levenshtein distance is a string metric for measuring the difference\n",
        "    between two sequences. Informally, the levenshtein disctance is defined as\n",
        "    the minimum number of single-character edits (substitutions, insertions or\n",
        "    deletions) required to change one word into the other. We can naturally\n",
        "    extend the edits to word level when calculate levenshtein disctance for\n",
        "    two sentences.\n",
        "    \"\"\"\n",
        "    m = len(ref)\n",
        "    n = len(hyp)\n",
        "\n",
        "    # special case\n",
        "    if ref == hyp:\n",
        "        return 0\n",
        "    if m == 0:\n",
        "        return n\n",
        "    if n == 0:\n",
        "        return m\n",
        "\n",
        "    if m < n:\n",
        "        ref, hyp = hyp, ref\n",
        "        m, n = n, m\n",
        "\n",
        "    # use O(min(m, n)) space\n",
        "    distance = np.zeros((2, n + 1), dtype=np.int32)\n",
        "\n",
        "    # initialize distance matrix\n",
        "    for j in range(0,n + 1):\n",
        "        distance[0][j] = j\n",
        "\n",
        "    # calculate levenshtein distance\n",
        "    for i in range(1, m + 1):\n",
        "        prev_row_idx = (i - 1) % 2\n",
        "        cur_row_idx = i % 2\n",
        "        distance[cur_row_idx][0] = i\n",
        "        for j in range(1, n + 1):\n",
        "            if ref[i - 1] == hyp[j - 1]:\n",
        "                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n",
        "            else:\n",
        "                s_num = distance[prev_row_idx][j - 1] + 1\n",
        "                i_num = distance[cur_row_idx][j - 1] + 1\n",
        "                d_num = distance[prev_row_idx][j] + 1\n",
        "                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n",
        "\n",
        "    return distance[m % 2][n]\n",
        "\n",
        "\n",
        "def word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
        "    hypothesis sequence in word-level.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param delimiter: Delimiter of input sentences.\n",
        "    :type delimiter: char\n",
        "    :return: Levenshtein distance and word number of reference sentence.\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    ref_words = reference.split(delimiter)\n",
        "    hyp_words = hypothesis.split(delimiter)\n",
        "\n",
        "    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n",
        "    return float(edit_distance), len(ref_words)\n",
        "\n",
        "\n",
        "def char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
        "    hypothesis sequence in char-level.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param remove_space: Whether remove internal space characters\n",
        "    :type remove_space: bool\n",
        "    :return: Levenshtein distance and length of reference sentence.\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    join_char = ' '\n",
        "    if remove_space == True:\n",
        "        join_char = ''\n",
        "\n",
        "    reference = join_char.join(filter(None, reference.split(' ')))\n",
        "    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n",
        "\n",
        "    edit_distance = _levenshtein_distance(reference, hypothesis)\n",
        "    return float(edit_distance), len(reference)\n",
        "\n",
        "\n",
        "def wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    \"\"\"Calculate word error rate (WER). WER compares reference text and\n",
        "    hypothesis text in word-level. WER is defined as:\n",
        "    .. math::\n",
        "        WER = (Sw + Dw + Iw) / Nw\n",
        "    where\n",
        "    .. code-block:: text\n",
        "        Sw is the number of words subsituted,\n",
        "        Dw is the number of words deleted,\n",
        "        Iw is the number of words inserted,\n",
        "        Nw is the number of words in the reference\n",
        "    We can use levenshtein distance to calculate WER. Please draw an attention\n",
        "    that empty items will be removed when splitting sentences by delimiter.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param delimiter: Delimiter of input sentences.\n",
        "    :type delimiter: char\n",
        "    :return: Word error rate.\n",
        "    :rtype: float\n",
        "    :raises ValueError: If word number of reference is zero.\n",
        "    \"\"\"\n",
        "    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n",
        "                                         delimiter)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Reference's word number should be greater than 0.\")\n",
        "\n",
        "    wer = float(edit_distance) / ref_len\n",
        "    return wer\n",
        "\n",
        "\n",
        "def cer(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    \"\"\"Calculate charactor error rate (CER). CER compares reference text and\n",
        "    hypothesis text in char-level. CER is defined as:\n",
        "    .. math::\n",
        "        CER = (Sc + Dc + Ic) / Nc\n",
        "    where\n",
        "    .. code-block:: text\n",
        "        Sc is the number of characters substituted,\n",
        "        Dc is the number of characters deleted,\n",
        "        Ic is the number of characters inserted\n",
        "        Nc is the number of characters in the reference\n",
        "    We can use levenshtein distance to calculate CER. Chinese input should be\n",
        "    encoded to unicode. Please draw an attention that the leading and tailing\n",
        "    space characters will be truncated and multiple consecutive space\n",
        "    characters in a sentence will be replaced by one space character.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param remove_space: Whether remove internal space characters\n",
        "    :type remove_space: bool\n",
        "    :return: Character error rate.\n",
        "    :rtype: float\n",
        "    :raises ValueError: If the reference length is zero.\n",
        "    \"\"\"\n",
        "    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n",
        "                                         remove_space)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Length of reference should be greater than 0.\")\n",
        "\n",
        "    cer = float(edit_distance) / ref_len\n",
        "    return cer\n",
        "\n",
        "\n",
        "\n",
        "def GreedyDecoder(output, labels, label_lengths, blank_label=(31 + 2 + 1) if PERSIAN_FLAG else (28+2), collapse_repeated=True):\n",
        "\targ_maxes = torch.argmax(output, dim=2)\n",
        "\tdecodes = []\n",
        "\ttargets = []\n",
        "\tfor i, args in enumerate(arg_maxes):\n",
        "\t\tdecode = []\n",
        "\t\ttargets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
        "\t\tfor j, index in enumerate(args):\n",
        "\t\t\tif index != blank_label:\n",
        "\t\t\t\tif collapse_repeated and j != 0 and index == args[j -1]:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tdecode.append(index.item())\n",
        "\t\tdecodes.append(text_transform.int_to_text(decode))\n",
        "\treturn decodes, targets\n",
        "\n",
        "def SEQ2SEQ_Decoder(spectrograms, model, labels, label_lengths, input_lengths):\n",
        "\n",
        "\t# decodes = model.greedy_decode(spectrograms, input_lengths)\n",
        "  decodes = model.beam_decode(spectrograms, input_lengths)\n",
        "  targets = []\n",
        "  for i, args in enumerate(spectrograms):\n",
        "    decode = []\n",
        "    targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
        "  return decodes, targets\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSm2uHaTElDT",
        "colab_type": "text"
      },
      "source": [
        "# Train and Valid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69qwgnoODdox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch , writer, limit = None, loss_tracker = []):\n",
        "  model.train()\n",
        "  data_len = 0\n",
        "\n",
        "  loss_avg = 0\n",
        "               \n",
        "  for batch_idx, _data in tqdm (enumerate(train_loader) , total = len (train_loader)):\n",
        "      \n",
        "      waveforms, spectrograms, labels, input_lengths, label_lengths = _data \n",
        "      spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "      batch_size = len (spectrograms)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      if SEQ2SEQ_Training:\n",
        "        output = model(spectrograms, labels, input_lengths)\n",
        "        loss = -output.sum()/ batch_size\n",
        "      else:\n",
        "        output = model(spectrograms)  # (batch, time, n_class)\n",
        "        output = F.log_softmax(output, dim=2)\n",
        "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "      \n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "      # scheduler.step()\n",
        "       \n",
        "      \n",
        "      loss_avg = (loss_avg * data_len + loss.item() * batch_size) / (data_len + batch_size)\n",
        "      data_len += batch_size\n",
        "      \n",
        "\n",
        "      del loss , spectrograms, labels\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      if limit is not None and data_len > limit:\n",
        "        return\n",
        "      \n",
        "      if batch_idx % 50 == 0:\n",
        "          print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "              epoch, batch_idx * batch_size, len(train_loader.dataset),\n",
        "              100. * batch_idx / len (train_loader), loss_avg))\n",
        "  loss_tracker.append(loss_avg)\n",
        "  writer.add_scalar(\"Loss/Train\", loss_avg, global_step=epoch)\n",
        "  writer.flush()\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, criterion, epoch, writer , complete_report = False, loss_tracker = []):\n",
        "  print('\\nevaluating...')\n",
        "  model.eval()\n",
        "  \n",
        "  loss_avg = 0\n",
        "  data_len = 0\n",
        "\n",
        "  test_cer, test_wer = [], []\n",
        "  \n",
        "  batch_idx = 0\n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for batch_idx , _data in tqdm (enumerate(test_loader), total = len (test_loader)):\n",
        "          waveforms, spectrograms, labels, input_lengths, label_lengths = _data \n",
        "          spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "          batch_size = len (spectrograms)\n",
        "\n",
        "          if SEQ2SEQ_Training:\n",
        "            output = model(spectrograms, labels,input_lengths)\n",
        "            loss = -output.sum()/ batch_size\n",
        "          else:\n",
        "            output = model(spectrograms)  # (batch, time, n_class)\n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "\n",
        "          loss_avg = (loss_avg * data_len + loss.item() * batch_size) / (data_len + batch_size)\n",
        "          data_len += batch_size\n",
        "\n",
        "          if SEQ2SEQ_Training:\n",
        "            decoded_preds, decoded_targets = SEQ2SEQ_Decoder(spectrograms, model, labels, label_lengths, input_lengths)\n",
        "          else:\n",
        "            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
        "\n",
        "          del loss , spectrograms, labels\n",
        "          torch.cuda.empty_cache()\n",
        "\n",
        "          for j in range(len(decoded_preds)):\n",
        "            test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
        "            test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
        "\n",
        "            if complete_report:\n",
        "              string = \"Final report:\\n\" + decoded_targets[j] +  \"   ***|||***   Predicted:\\n\" + decoded_preds[j]\n",
        "              writer.add_audio(tag = string, snd_tensor = waveforms[j], global_step=epoch, sample_rate=sample_rate)\n",
        "\n",
        "          if batch_idx % 100 == 0:\n",
        "            if not complete_report:\n",
        "              string = str(epoch) + \"Real:\\n\" + decoded_targets[0] + \"   ***|||***   Predicted:\\n\" + decoded_preds[0]\n",
        "              writer.add_audio(tag = string, snd_tensor = waveforms[0], global_step=epoch, sample_rate=sample_rate)\n",
        "\n",
        "            avg_cer = sum(test_cer)/len(test_cer)\n",
        "            avg_wer = sum(test_wer)/len(test_wer)\n",
        "            print (\"preds:\" , decoded_preds[0])\n",
        "            print (\"targets:\" , decoded_targets[0])\n",
        "            print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(loss_avg, avg_cer, avg_wer))\n",
        "\n",
        "\n",
        "  avg_cer = sum(test_cer)/len(test_cer)\n",
        "  avg_wer = sum(test_wer)/len(test_wer)\n",
        "  \n",
        "  \n",
        "  if not complete_report:\n",
        "    loss_tracker.append(loss_avg)\n",
        "    writer.add_scalar(\"Loss/Test\", loss_avg, global_step=epoch)\n",
        "    writer.add_scalar(\"CER/Test\", avg_cer, global_step=epoch)\n",
        "    writer.add_scalar(\"WER/Test\", avg_wer, global_step=epoch)\n",
        "    writer.flush()\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVaXvxm-FH4d",
        "colab_type": "text"
      },
      "source": [
        "# Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEXYX6HiSvVC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "outputId": "5d3edf7b-b999-444b-9414-b1b8c8e3a31e"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "logdir = \"/content/ASR/__13_\"\n",
        "\n",
        "writer = SummaryWriter(logdir)\n",
        "\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"ASR\""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = await google.colab.kernel.proxyPort(6006, {\"cache\": true});\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4i12U14FNh0",
        "colab_type": "text"
      },
      "source": [
        "# Train loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZM86DHeyp93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "save_path = \"/content/drive/My Drive/ASR/seq2seq_english\""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjT_rbetsxhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_tracker_train = []\n",
        "loss_tracker_test = []\n",
        "\n",
        "epoch = None"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQQbhNbi2apS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a81eb0c85f0644edb7feceb93a084c39",
            "413a8411954049418e5fc6029027eb0a",
            "31e702ce423a48a7a5ac263bccdf883c",
            "4cd3db52c9da4bf7ad6173cf50784593",
            "ad10c9ea12a0487496e1ccb04f61d950",
            "2758f1a1ea8b4cdb9caed963456d7fd5",
            "e5dcdd27684c4e3da2d3f03ec84e8359",
            "33a50a619db64354a5d5ca1c8e3c01a2",
            "cf36805f6e4d432298224e26fd266d66",
            "709af5dfe5244d2fb705e069aa225de6",
            "66fcb86315e44be792e0a28146ebff95",
            "95bf944069d64015a832b75616069fe0",
            "368c0f6781814a53b120332e39c25ae9",
            "653b36a066d84110b0ce0e505f81e929",
            "9348a325f57e46e09e6fdcd25c532214",
            "5deff977b531462789f4ae9881189862",
            "4b667943d37c493ca3737a54165aa2eb",
            "f5b7bbd541734403bb4f6fc922db570e",
            "f5afb6c0215743ebaf9d6a067c8a2d22",
            "39ea558049294a0da15c01dc8a259604",
            "552d4028a5eb46a8aa9af5534c5d938c",
            "7b3a03a5f7b144a59e8ce131d32f8f93",
            "c7c8b68f107043e3aa163cc7c1b42de3",
            "bdef48c7b50f45c9853d888824810579",
            "ca2cea92f68648849714d35a8d2d9381",
            "01583f42a5ed49c594757ff2c558aa62",
            "91c7ffc8d940488482cbebf1e94fff14",
            "b8e44b1889ed476591af01f855cb4c5b",
            "c68f7a32efaa4cc68fc2d779cffd2ca0",
            "68a382f229fe4eada7c67554d61dd59e",
            "29247ee0477d40ac97f37016cfb7a2c4",
            "55e4ed0c453e4aa6b32877a899c25e11"
          ]
        },
        "outputId": "f4ad87bd-c623-4519-c2d3-6e54646df2df"
      },
      "source": [
        "\n",
        "for epoch in tqdm (range (epochs)):\n",
        "  train(model, device, train_loader, criterion, optimizer, scheduler, epoch , writer, limit = None, loss_tracker = loss_tracker_train)\n",
        "  test(model, device, test_loader, criterion, epoch, writer, loss_tracker = loss_tracker_test)\n",
        "  print (\"lr:\" , get_lr(optimizer))\n",
        "  scheduler.step()\n",
        "  \n",
        "  # plt.plot (loss_tracker_train)\n",
        "  # plt.plot (loss_tracker_test)\n",
        "  # plt.show()\n",
        "  \n",
        "  torch.save ([loss_tracker_train, loss_tracker_test] , save_path + \"_loss_plot\")\n",
        "  torch.save(model.state_dict(), save_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a81eb0c85f0644edb7feceb93a084c39",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf36805f6e4d432298224e26fd266d66",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2854.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/28539 (0%)]\tLoss: 716.888184\n",
            "Train Epoch: 0 [500/28539 (2%)]\tLoss: 444.912213\n",
            "Train Epoch: 0 [1000/28539 (4%)]\tLoss: 412.096726\n",
            "Train Epoch: 0 [1500/28539 (5%)]\tLoss: 392.209155\n",
            "Train Epoch: 0 [2000/28539 (7%)]\tLoss: 377.055853\n",
            "Train Epoch: 0 [2500/28539 (9%)]\tLoss: 366.545392\n",
            "Train Epoch: 0 [3000/28539 (11%)]\tLoss: 356.237536\n",
            "Train Epoch: 0 [3500/28539 (12%)]\tLoss: 348.881183\n",
            "Train Epoch: 0 [4000/28539 (14%)]\tLoss: 342.105349\n",
            "Train Epoch: 0 [4500/28539 (16%)]\tLoss: 336.208154\n",
            "Train Epoch: 0 [5000/28539 (18%)]\tLoss: 331.016915\n",
            "Train Epoch: 0 [5500/28539 (19%)]\tLoss: 326.815054\n",
            "Train Epoch: 0 [6000/28539 (21%)]\tLoss: 323.811165\n",
            "Train Epoch: 0 [6500/28539 (23%)]\tLoss: 320.491322\n",
            "Train Epoch: 0 [7000/28539 (25%)]\tLoss: 317.761646\n",
            "Train Epoch: 0 [7500/28539 (26%)]\tLoss: 314.697943\n",
            "Train Epoch: 0 [8000/28539 (28%)]\tLoss: 312.133504\n",
            "Train Epoch: 0 [8500/28539 (30%)]\tLoss: 309.720094\n",
            "Train Epoch: 0 [9000/28539 (32%)]\tLoss: 307.270501\n",
            "Train Epoch: 0 [9500/28539 (33%)]\tLoss: 305.391153\n",
            "Train Epoch: 0 [10000/28539 (35%)]\tLoss: 303.781452\n",
            "Train Epoch: 0 [10500/28539 (37%)]\tLoss: 302.097981\n",
            "Train Epoch: 0 [11000/28539 (39%)]\tLoss: 300.472112\n",
            "Train Epoch: 0 [11500/28539 (40%)]\tLoss: 298.787310\n",
            "Train Epoch: 0 [12000/28539 (42%)]\tLoss: 297.221846\n",
            "Train Epoch: 0 [12500/28539 (44%)]\tLoss: 295.797407\n",
            "Train Epoch: 0 [13000/28539 (46%)]\tLoss: 294.230709\n",
            "Train Epoch: 0 [13500/28539 (47%)]\tLoss: 293.053739\n",
            "Train Epoch: 0 [14000/28539 (49%)]\tLoss: 291.629033\n",
            "Train Epoch: 0 [14500/28539 (51%)]\tLoss: 290.701521\n",
            "Train Epoch: 0 [15000/28539 (53%)]\tLoss: 289.560173\n",
            "Train Epoch: 0 [15500/28539 (54%)]\tLoss: 288.319973\n",
            "Train Epoch: 0 [16000/28539 (56%)]\tLoss: 287.547934\n",
            "Train Epoch: 0 [16500/28539 (58%)]\tLoss: 286.744119\n",
            "Train Epoch: 0 [17000/28539 (60%)]\tLoss: 285.798435\n",
            "Train Epoch: 0 [17500/28539 (61%)]\tLoss: 284.820947\n",
            "Train Epoch: 0 [18000/28539 (63%)]\tLoss: 283.870984\n",
            "Train Epoch: 0 [18500/28539 (65%)]\tLoss: 283.143289\n",
            "Train Epoch: 0 [19000/28539 (67%)]\tLoss: 282.361689\n",
            "Train Epoch: 0 [19500/28539 (68%)]\tLoss: 281.603053\n",
            "Train Epoch: 0 [20000/28539 (70%)]\tLoss: 281.052149\n",
            "Train Epoch: 0 [20500/28539 (72%)]\tLoss: 280.236348\n",
            "Train Epoch: 0 [21000/28539 (74%)]\tLoss: 279.597979\n",
            "Train Epoch: 0 [21500/28539 (75%)]\tLoss: 278.941906\n",
            "Train Epoch: 0 [22000/28539 (77%)]\tLoss: 278.322286\n",
            "Train Epoch: 0 [22500/28539 (79%)]\tLoss: 277.799452\n",
            "Train Epoch: 0 [23000/28539 (81%)]\tLoss: 277.240581\n",
            "Train Epoch: 0 [23500/28539 (82%)]\tLoss: 276.663067\n",
            "Train Epoch: 0 [24000/28539 (84%)]\tLoss: 276.218059\n",
            "Train Epoch: 0 [24500/28539 (86%)]\tLoss: 275.750703\n",
            "Train Epoch: 0 [25000/28539 (88%)]\tLoss: 275.352062\n",
            "Train Epoch: 0 [25500/28539 (89%)]\tLoss: 274.968125\n",
            "Train Epoch: 0 [26000/28539 (91%)]\tLoss: 274.605738\n",
            "Train Epoch: 0 [26500/28539 (93%)]\tLoss: 274.157617\n",
            "Train Epoch: 0 [27000/28539 (95%)]\tLoss: 273.704213\n",
            "Train Epoch: 0 [27500/28539 (96%)]\tLoss: 273.306396\n",
            "Train Epoch: 0 [28000/28539 (98%)]\tLoss: 272.849746\n",
            "Train Epoch: 0 [28500/28539 (100%)]\tLoss: 272.366212\n",
            "\n",
            "\n",
            "evaluating...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b667943d37c493ca3737a54165aa2eb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=262.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "preds: <there was therefore>\n",
            "targets: <can one imagine a naturalist refusing to study the viper the bat the scorpion the centipede the tarantula and one who would cast them back into their darkness saying oh how ugly that is>\n",
            "Test set: Average loss: 149.3741, Average CER: 0.821242 Average WER: 1.0208\n",
            "\n",
            "preds: <there was therefore>\n",
            "targets: <by being studious of color they are studious of division and while the chiaroscurist devotes himself to the representation of degrees of force in one thing unseparated light the colorists have for their function the attainment of beauty by arrangement of the divisions of light>\n",
            "Test set: Average loss: 142.5363, Average CER: 0.824657 Average WER: 1.0321\n",
            "\n",
            "preds: <there was there was therefore>\n",
            "targets: <may we see gates at once asked kenneth>\n",
            "Test set: Average loss: 144.0707, Average CER: 0.822366 Average WER: 1.0325\n",
            "\n",
            "\n",
            "lr: 0.001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca2cea92f68648849714d35a8d2d9381",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2854.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/28539 (0%)]\tLoss: 217.720612\n",
            "Train Epoch: 1 [500/28539 (2%)]\tLoss: 247.652871\n",
            "Train Epoch: 1 [1000/28539 (4%)]\tLoss: 245.034525\n",
            "Train Epoch: 1 [1500/28539 (5%)]\tLoss: 245.759277\n",
            "Train Epoch: 1 [2000/28539 (7%)]\tLoss: 246.773401\n",
            "Train Epoch: 1 [2500/28539 (9%)]\tLoss: 247.170222\n",
            "Train Epoch: 1 [3000/28539 (11%)]\tLoss: 247.326852\n",
            "Train Epoch: 1 [3500/28539 (12%)]\tLoss: 246.469319\n",
            "Train Epoch: 1 [4000/28539 (14%)]\tLoss: 246.030049\n",
            "Train Epoch: 1 [4500/28539 (16%)]\tLoss: 245.962710\n",
            "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 246.172793\n",
            "Train Epoch: 1 [5500/28539 (19%)]\tLoss: 246.462745\n",
            "Train Epoch: 1 [6000/28539 (21%)]\tLoss: 246.373859\n",
            "Train Epoch: 1 [6500/28539 (23%)]\tLoss: 246.095818\n",
            "Train Epoch: 1 [7000/28539 (25%)]\tLoss: 246.016381\n",
            "Train Epoch: 1 [7500/28539 (26%)]\tLoss: 246.201594\n",
            "Train Epoch: 1 [8000/28539 (28%)]\tLoss: 246.381119\n",
            "Train Epoch: 1 [8500/28539 (30%)]\tLoss: 246.180495\n",
            "Train Epoch: 1 [9000/28539 (32%)]\tLoss: 246.251189\n",
            "Train Epoch: 1 [9500/28539 (33%)]\tLoss: 246.084022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_s9bRMCgqLw",
        "colab_type": "text"
      },
      "source": [
        "# Final Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS7cZPk1MCRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_tracker_train, loss_tracker_test = torch.load (save_path + \"_loss_plot\")\n",
        "\n",
        "plt.plot (loss_tracker_train)\n",
        "plt.plot (loss_tracker_test)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HriwcY9sWGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtnRTf34yjML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(torch.load(save_path))\n",
        "if epoch is None:\n",
        "  epoch = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsS-i4_9RcV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test(model, device, test_loader, criterion, epoch, writer , complete_report=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zQ-otZni5Hx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "USE_LM_Model = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m99LhcrtkkDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test(model, device, test_loader, criterion, epoch, writer , complete_report=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}